import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import r2_score, mean_absolute_error

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ Ø£Ù†Ø´Ø£Ù†Ø§Ù‡Ø§
from src.config import DATA_PATH, MODEL_PATH
from src.features import FEATURES_NUMERIC, FEATURES_CATEGORICAL, TARGET_COLUMN
from src.data_loader import load_data

def train_price_model(df=None):
    """
    ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Random Forest Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
    """
    print("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    if df is None:
        df = load_data(DATA_PATH)

    # 1. ÙØµÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¹Ù† Ø§Ù„Ù‡Ø¯Ù
    X = df[FEATURES_NUMERIC + FEATURES_CATEGORICAL]
    y = df[TARGET_COLUMN]

    # 2. Ø§Ù„Ø³Ø± ÙÙŠ Ø±ÙØ¹ R2: ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³Ø¹Ø± Ù„Ù„ÙˆØºØ§Ø±ÙŠØªÙ… Ù„ØªÙ‚Ù„ÙŠÙ„ Ø£Ø«Ø± Ø§Ù„ÙØ¬ÙˆØ§Øª Ø§Ù„Ø³Ø¹Ø±ÙŠØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
    y_log = np.log1p(y)

    # 3. Ø¨Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Preprocessing)
    # StandardScaler Ù„Ù„Ø£Ø±Ù‚Ø§Ù… Ùˆ OneHotEncoder Ù„Ù„Ù†ØµÙˆØµ
    numeric_transformer = StandardScaler()
    categorical_transformer = OneHotEncoder(handle_unknown='ignore')

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, FEATURES_NUMERIC),
            ('cat', categorical_transformer, FEATURES_CATEGORICAL)
        ])

    # 4. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ø³ØªØ®Ø¯Ø§Ù… RandomForestRegressor Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ø®Ø·ÙŠØ©)
    model = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('regressor', RandomForestRegressor(
            n_estimators=300,   # Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø¬Ø§Ø±
            max_depth=20,       # Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù…Ù†Ø¹ Overfitting
            min_samples_split=5,
            random_state=42     # Ù„Ø¶Ù…Ø§Ù† Ø«Ø¨Ø§Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¹Ù†Ø¯ ÙƒÙ„ ØªØ´ØºÙŠÙ„
        ))
    ])

    # 5. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (80% ØªØ¯Ø±ÙŠØ¨ØŒ 20% Ø§Ø®ØªØ¨Ø§Ø±)
    X_train, X_test, y_train, y_test = train_test_split(X, y_log, test_size=0.2, random_state=42)

    print(f"ğŸš€ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ {len(X_train)} Ø¹ÙŠÙ†Ø©...")
    model.fit(X_train, y_train)

    # 6. Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    y_pred_log = model.predict(X_test)
    r2 = r2_score(y_test, y_pred_log)
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¨Ø§Ù„Ø¯ÙˆÙ„Ø§Ø± (Ø¹Ø¨Ø± Ø¹ÙƒØ³ Ø§Ù„Ù„ÙˆØºØ§Ø±ÙŠØªÙ…)
    actual_prices = np.expm1(y_test)
    predicted_prices = np.expm1(y_pred_log)
    mae = mean_absolute_error(actual_prices, predicted_prices)

    print("\n" + "="*30)
    print(f"âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"ğŸ“Š Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (RÂ² Score): {r2:.4f}")
    print(f"ğŸ’° Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…Ø·Ù„Ù‚: {mae:,.2f} Ø¯ÙˆÙ„Ø§Ø±")
    print("="*30)

    # 7. Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Bundle)
    bundle = {
        "pipeline": model,
        "features_used": FEATURES_NUMERIC + FEATURES_CATEGORICAL,
        "metrics": {"r2": r2, "mae": mae},
        "use_log_target": True
    }
    
    joblib.dump(bundle, MODEL_PATH)
    print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {MODEL_PATH}")
    
    return bundle

if __name__ == "__main__":
    train_price_model()